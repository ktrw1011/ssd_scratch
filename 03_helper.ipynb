{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42777f93-abe9-4046-826c-f0151c82d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543ccf0-ffd4-4ca0-9f7d-fd3598d7400f",
   "metadata": {},
   "source": [
    "# デフォルトボックスからバウンディングボックスへの変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85bbbf26-86b2-4981-9f11-b56f904aba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(loc, dbox_list):\n",
    "    '''\n",
    "    locネットワークが出力するオフセット情報を使用してDBoxをBBoxに変換する\n",
    "\n",
    "    Parameters:\n",
    "      loc(Tensor):\n",
    "        locが出力する(8732,4)の形状のテンソル\n",
    "        8,732個のDBoxのオフセット情報(Δcx, Δcy, Δwidth, Δheight)\n",
    "      dbox_list(Tensor):\n",
    "        DBoxの情報(cx, cy, width, height)を格納した(8732,4)のテンソル\n",
    "        \n",
    "    Returns(Tensor):\n",
    "      BBoxの情報(xmin, ymin, xmax, ymax)を格納したテンソル(8732, 4)\n",
    "    '''\n",
    "    # DBoxにlocのオフセットを適用してBBoxの(cx, cy, width, height)を求める\n",
    "    # 変数boxesの形状は(8732, 4)\n",
    "    boxes = torch.cat((\n",
    "        # cx = cx_d + 0.1Δcx ･ w_d\n",
    "        # cy = cy_d + 0.1Δcy ･ h_d\n",
    "        dbox_list[:, :2] + loc[:, :2] * 0.1 * dbox_list[:, 2:],\n",
    "        # w = w_d ･ exp(0.2Δw)\n",
    "        # h = h_d ･ exp(0.2Δh)\n",
    "        dbox_list[:, 2:] * torch.exp(loc[:, 2:] * 0.2)\n",
    "        ),dim=1)\n",
    "\n",
    "    # BBoxの情報(cx, cy, width, height)を(xmin, ymin, xmax, ymax)に変換\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2  # (cx, cy)を(xmin,ymin)にする\n",
    "    boxes[:, 2:] += boxes[:, :2]      # (width, height)を(xmax,ymax)にする\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02e776-aa78-4260-ba6f-a2d87dddbf1b",
   "metadata": {},
   "source": [
    "デコード関数はモデルが学習したデフォルトボックスの位置情報をバウンディングボックスに変換する関数  \n",
    "ssdのネットワークにはデフォルトボックスの位置情報を持っている(cx_d, cy_d, w_d, h_d)  \n",
    "これに対して、物体中心へのデフォルトボックスのオフセット値を出力する(⊿cx, ⊿cy, ⊿w, ⊿y)  \n",
    "\n",
    "この2つの情報を元にバウンディングボックスの座標を計算する  \n",
    "$$\n",
    "    cx = cx\\_d(1+0.1\\Delta cx) \\\\\n",
    "    cy = cy\\_d(1+0.1\\Delta cy) \\\\\n",
    "    w = w\\_d \\times exp(0.2\\Delta w) \\\\\n",
    "    h = h\\_d \\times exp(0.2\\Delta h)\n",
    "$$\n",
    "\n",
    "これは理論的に決まっているのではなく、このように元のバウンディングボックスの座標を変換するように学習することを定めている(なぜこうなのかは不明)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e0c90-4fc0-47b0-b45a-ee33bc1130f6",
   "metadata": {},
   "source": [
    "# Non-Maximum Supression\n",
    "バウンディングの被りの処理  \n",
    "<img src=\"https://cvml-expertguide.net/wp-content/uploads/2022/08/07e652a1b89611f1c0aa98bc50c80ac6.png\" width=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d201d3-1cb0-4cde-a0f9-92486c4a6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonmaximum_suppress(\n",
    "        boxes, scores, overlap=0.5, top_k=200): ###### nm_suppressionを変更、オリジナルの0.5に戻す######\n",
    "    '''1つの物体に対して1つのBBoxだけを残す\n",
    "    \n",
    "    画像分類のクラスごとにNon-Maximum Suppressionを実施\n",
    "    クラス単位で抽出された確信度0.01以上のboxesから同一の物体に対する被り度\n",
    "    （IoU値）が大きいBBoxを集めて、その中で最大の確信度を持つBBoxだけを取り出す\n",
    "\n",
    "    Parameters:\n",
    "      boxes(Tensor):\n",
    "        1クラスあたり8,732個のBBoxのうち、確信度0.01を超えたDBoxの座標情報\n",
    "        テンソルの形状は(1クラスにつき確信度0.01を超えたDBoxの数, 4)\n",
    "      scores(Tensor):\n",
    "          confネットワークの出力(DBoxの各クラスの確信度)からクラスごとに\n",
    "          確信度の閾値0.01を超えるBBoxの確信度だけを抜き出したもの\n",
    "          テンソルの形状は(1クラスにつき確信度0.01を超えたBBoxの数, )\n",
    "      overlap(float):\n",
    "        被り度合い（IoU値）の基準にする値\n",
    "        overlapが0.5以上である場合に、それらのバウンディングボックスは\n",
    "        同じ物体に対するバウンディングボックスと判断する\n",
    "      top_k(int)\n",
    "　      scoresから確信度が高い順にサンプルを取り出す際の、取り出すサンプルの数\n",
    "\n",
    "    Returns:\n",
    "      keep(Tensor): 画像中に存在するBBoxのインデックスが格納される\n",
    "      count(int):  画像中に存在するBBoxの数が格納される\n",
    "    '''\n",
    "    # NMSを通過したBBoxの数を保持する変数の初期化\n",
    "    count = 0\n",
    "    # scoresと同じ形状の0で初期化したテンソルを生成\n",
    "    # keepの形状は(1クラスにつき確信度0.01を超えたBBoxの数,)\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "\n",
    "    # 各BBoxの面積areaを計算\n",
    "    # areaの形状は(確信度0.01を超えるBBoxの数,)\n",
    "    x1 = boxes[:, 0] # x軸最小値\n",
    "    y1 = boxes[:, 1] # y軸最小値\n",
    "    x2 = boxes[:, 2] # x軸最大値\n",
    "    y2 = boxes[:, 3] # y軸最大値\n",
    "    area = torch.mul(x2 - x1, y2 - y1) # torch.mulで底辺×高さを求める\n",
    "\n",
    "    # boxesのコピーをBBox情報の要素の数だけ作成\n",
    "    # BBoxの被り度(IoU)の計算の際に使用する\n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "\n",
    "    # socreを昇順(確信度が低い方から)に並び変える\n",
    "    v, idx = scores.sort(0) # idxに元の要素のインデックスのリストを格納\n",
    "\n",
    "    # idxの上位top_k個（200個）のBBoxのインデックスを取り出す\n",
    "    # 200個存在しない場合もある\n",
    "    idx = idx[-top_k:]\n",
    "\n",
    "    # idx(初期の要素数top_k個（200個）)の要素数が0でない限りループ\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # 最大の確信度(conf値)のインデックスを取得\n",
    "        \n",
    "        # keepの形状は(1クラスにつき確信度0.01を超えたBBoxの数,)\n",
    "        # keepのインデックスcountの位置に最大確信度(conf値)のインデックス値を格納\n",
    "        # このインデックスのBBoxと被りが大きいBBoxを以下の処理で取り除く\n",
    "        keep[count] = i\n",
    "        # keepのインデックスを1増やす\n",
    "        count += 1\n",
    "\n",
    "        # idxの要素数を取得し、1(最後のBBox)であればループを抜ける\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "\n",
    "        ### Non-Maximum Suppressionの処理を開始 ###\n",
    "        # 昇順に並んでいるscoresのインデックスの末尾を除外する\n",
    "        idx = idx[:-1]\n",
    "\n",
    "        # idxの昇順スコアのインデックス値を使ってBBoxの座標情報xmin, ymin, xmax, ymaxの\n",
    "        # 情報を抽出してtmp_x1、tmp_y1、tmp_x2、tmp_y2に格納\n",
    "        # index_select(入力Tensor,\n",
    "        #              対象の次元,\n",
    "        #              抽出する要素のインデックス,\n",
    "        #              out=出力Tensor名)\n",
    "        torch.index_select(x1, 0, idx, out=tmp_x1) # 昇順スコアに対応するxminの並び\n",
    "        torch.index_select(y1, 0, idx, out=tmp_y1) # 昇順スコアに対応するyminの並び\n",
    "        torch.index_select(x2, 0, idx, out=tmp_x2) # 昇順スコアに対応するxmaxの並び\n",
    "        torch.index_select(y2, 0, idx, out=tmp_y2) # 昇順スコアに対応するymaxの並び\n",
    "\n",
    "        # idxに残っているBBoxのxmin, ymin, xmax, ymaxの下限値を\n",
    "        # それぞれインデックスi(確信度最上位のBBox）の値までに切り詰める\n",
    "        # torch.clamp(入力Tensor,\n",
    "        #             min=切り詰める下限値,\n",
    "        #             max=切り詰める上限値,\n",
    "        #             out=出力Tensor名)\n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i]) # xminの下限値を切り詰める\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i]) # yminの下限値を切り詰める\n",
    "        tmp_x2 = torch.clamp(tmp_x2, max=x2[i]) # xmaxの下限値を切り詰める\n",
    "        tmp_y2 = torch.clamp(tmp_y2, max=y2[i]) # xmaxの下限値を切り詰める\n",
    "\n",
    "        # tmp_wとtmp_hのテンソルの形状をそれぞれtmp_x2、tmp_y2と同じ形状にする\n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "\n",
    "        # tmp_x1, tmp_y1, tmp_x2, tmp_y2を使って重なる部分の幅と高さを求め\n",
    "        # tmp_wとtmp_hに代入する\n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "\n",
    "        # 幅や高さが負の値になっていたら0にする\n",
    "        tmp_w = torch.clamp(tmp_w, min=0.0)\n",
    "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
    "\n",
    "        # intersect(交差)部分の面積(A ∩ B)を求める\n",
    "        inter = tmp_w*tmp_h\n",
    "\n",
    "        # IoU = intersect部分 / (area(a) + area(b) - intersect部分)の計算\n",
    "        # areaからidxに残っているすべてのBBoxの面積を取得\n",
    "        rem_areas = torch.index_select(\n",
    "            area, # 確信度0.01以上のすべてのBBoxの面積\n",
    "            0,    # 処理対象の次元\n",
    "            idx)  # 確信度上位200から現存するBBoxのインデックス値の並び\n",
    "        # (BBoxの元の面積 - 交差部分の面積)+基準となるBBox(確信度最上位）の面積\n",
    "        union = (rem_areas - inter) + area[i]  # A∪Bの面積\n",
    "        IoU = inter/union # idxに残っているすべてのBBoxのIoUを求める\n",
    "\n",
    "        # idxに残っているBBoxのうちIoUがoverlapより小さいものだけを残す\n",
    "        # 同じ物体を囲むその他のBBoxがすべて取り除かれる\n",
    "        idx = idx[IoU.le(overlap)]  # le()はoverlap以下の要素だけを残す\n",
    "\n",
    "    # idxのBBoxが１個になりwhileループを抜けたら\n",
    "    # 検出されたBBoxの数とBBoxを参照するためのインデックス値を返して終了\n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938c8c6-86d0-4020-8efa-f6a22e3c8c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
