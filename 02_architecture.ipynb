{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59589381-5e5c-402d-a4cc-db7fd1ff0437",
   "metadata": {},
   "source": [
    "# SSDの学習の流れ\n",
    "\n",
    "## 1. 画像のリサイズ\n",
    "300 x 300にリサイズする\n",
    "\n",
    "## 2. 画像をネットワークに入力\n",
    "モデルはvgg、extras、loc、confで構成される\n",
    "\n",
    "### loc\n",
    "SSDはバウンディングボックスの走査などの処理はせずに、様々なアスペクト比を持つデフォルトボックスと呼ばれる矩形を用意する(8743個)  \n",
    "このデフォルトボックスは元のデフォルトボックスの中心から差分を学習する。  \n",
    "こうすることでデフォルトボックスが物体の中心に寄るよう学習される\n",
    "\n",
    "学習前のデフォルトボックスの位置  \n",
    "<img src=\"https://avinton.com/wp-content/uploads/2018/03/11-1.png\" width=\"500\"/>  \n",
    "\n",
    "学習後のデフォルトボックスの位置  \n",
    "<img src=\"https://avinton.com/wp-content/uploads/2018/03/bl.png\" width=\"500\" />  \n",
    "\n",
    "学習前から学習後ではデフォルトの位置が中心に寄ることが分かる（点線が元）  \n",
    "（中心位置だけではなく高さと幅の差分も計算するのでそこから、ボックスの大きさも変わるっぽい）  \n",
    "<img src=\"https://avinton.com/wp-content/uploads/2018/03/8.png\" width=\"500\" />\n",
    "\n",
    "\n",
    "<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/k/kawam0t0/20191223/20191223123247.png\" width=\"600\">\n",
    "\n",
    "### conf\n",
    "デフォルトボックス毎にどのクラスが含まれているかを学習する  \n",
    "あとで、どのデフォルトボックスを最終的に残すかの判断に使用される\n",
    "\n",
    "参考\n",
    "- [【機械学習】一般物体検知アルゴリズム SSD : 第1編](https://avinton.com/blog/2018/03/single-shot-multibox-detector-explained1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc7cc54-c7fa-4cff-ad71-b15ad61bdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9a37f-4d9f-49a2-a6fe-68704a080f59",
   "metadata": {},
   "source": [
    "# vggアーキテクチャ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e6df21-ed09-4ca2-825b-7aa0df33511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vgg():\n",
    "    '''\n",
    "    Returns：\n",
    "      (nn.ModuleList): vggのモジュール(部品)のリスト\n",
    "    '''\n",
    "    layers = []      # モジュールを格納するリスト\n",
    "    in_channels = 3  # チャネル数はRGBの3値\n",
    "\n",
    "    # vggに配置する畳み込み層のフィルター数(チャネル数に相当)\n",
    "    # 'M''MC'はプーリング層を示す\n",
    "    cfg = [64, 64, 'M',         # vgg1\n",
    "           128, 128, 'M',       # vgg2\n",
    "           256, 256, 256, 'MC', # vgg3\n",
    "           512, 512, 512, 'M',  # vgg4\n",
    "           512, 512, 512        # vgg5\n",
    "           ]\n",
    "    # vgg1～vgg5の畳み込み層までを生成\n",
    "    for v in cfg:\n",
    "        # vgg1、vgg2、vgg4のプーリング層\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, # ウィンドウサイズ2×2\n",
    "                                    stride=2)]     # ストライド2\n",
    "        # vgg3のプーリング層\n",
    "        elif v == 'MC':\n",
    "            # vgg3のプーリングで(75, 75)の特徴量マップを半分のサイズにする際に、\n",
    "            # ceil_modeをTrueにすることで75/2=37.5を切り上げて38にする\n",
    "            # この結果、vgg3のプーリング層から出力される特徴量マップのサイズは\n",
    "            # (38, 38)になる\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, # ウィンドウサイズ2×2\n",
    "                                    stride=2,      # ストライド2\n",
    "                                    ceil_mode=True)]\n",
    "        # vgg1～vgg5の畳み込み層\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels,  # 入力時のチャネル数\n",
    "                               v,            # 出力時のチャネル数(フィルター数)\n",
    "                               kernel_size=3,# フィルターサイズ3×3\n",
    "                               padding=1)    # パディングのサイズは1\n",
    "            \n",
    "            # 畳み込み層に活性化関数ReLUをセットしてlayersに追加\n",
    "            # inplace=TrueにするとReLUへの入力値は保持されない(メモリ節約)\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            # チャネル数を出力時のチャネル数(フィルター数)に置き換える\n",
    "            in_channels = v\n",
    "            \n",
    "    # vgg5のプーリング層\n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, # ウィンドウサイズ3×3\n",
    "                         stride=1,      # ストライド1\n",
    "                         padding=1)     # パディングのサイズは1\n",
    "    # vgg6の畳み込み層1\n",
    "    conv6 = nn.Conv2d(512,  # 入力時のチャネル数\n",
    "                      1024, # 出力時のチャネル数(フィルター数)\n",
    "                      kernel_size=3,# フィルターサイズ3×3\n",
    "                      padding=6,    # パディングのサイズは6\n",
    "                      dilation=6)   # 畳み込みのポイント間の間隔を6にする\n",
    "    # vgg6の畳み込み層2\n",
    "    conv7 = nn.Conv2d(1024, # 入力時のチャネル数\n",
    "                      1024, # 出力時のチャネル数(フィルター数)\n",
    "                      kernel_size=1) # フィルターサイズ1×1\n",
    "    # vgg5のプーリング層、vgg6の畳み込み層1と畳み込み層2をlayersに追加\n",
    "    layers += [pool5,\n",
    "               conv6, nn.ReLU(inplace=True), # 畳み込みの活性化はReLU\n",
    "               conv7, nn.ReLU(inplace=True)] # 畳み込みの活性化はReLU\n",
    "    \n",
    "    # リストlayersをnn.ModuleListに格納してReturnする\n",
    "    return nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4a8c3d-6083-4317-8832-76f05f3dcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = make_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26447d5b-5fdc-4070-8b1c-3248f2a288d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 64, 300, 300])\n",
      "【Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 64, 300, 300])\n",
      "【MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)】 ==> torch.Size([4, 64, 150, 150])\n",
      "【Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 128, 150, 150])\n",
      "【Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 128, 150, 150])\n",
      "【MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)】 ==> torch.Size([4, 128, 75, 75])\n",
      "【Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 256, 75, 75])\n",
      "【Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 256, 75, 75])\n",
      "【Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 256, 75, 75])\n",
      "【MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)】 ==> torch.Size([4, 256, 38, 38])\n",
      "【Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 512, 38, 38])\n",
      "【Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 512, 38, 38])\n",
      "【Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 512, 38, 38])\n",
      "【MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)】 ==> torch.Size([4, 512, 19, 19])\n",
      "【Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 512, 19, 19])\n",
      "【Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 512, 19, 19])\n",
      "【Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 512, 19, 19])\n",
      "【MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)】 ==> torch.Size([4, 512, 19, 19])\n",
      "【Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))】 ==> torch.Size([4, 1024, 19, 19])\n",
      "【Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))】 ==> torch.Size([4, 1024, 19, 19])\n"
     ]
    }
   ],
   "source": [
    "sample = torch.randn((4, 3, 300, 300))\n",
    "with torch.no_grad():\n",
    "    for i, layer in enumerate(vgg):\n",
    "        sample = layer(sample)\n",
    "        if layer.__class__ != nn.modules.activation.ReLU:\n",
    "            print(f\"【{layer}】 ==> {sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891720f-0d2b-438f-a12a-bfa8b1ee8627",
   "metadata": {},
   "source": [
    "最終的に1024チャンネル、19x19の特徴量マップになる  \n",
    "vgg4までの特徴量マップはL2正則化されて、利用される  \n",
    "最後のvgg6まで通ったあとには、extrasモジュールによって再度畳み込みが実施される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7c50a-cafd-47f7-b768-3a3ee9c81de3",
   "metadata": {},
   "source": [
    "# 追加のレイヤー(extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7e2ebf-9cb2-4f9d-b349-5c3bd3e06748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_extras():\n",
    "    '''\n",
    "    Returns：\n",
    "      (nn.ModuleList): extrasのモジュール(部品)のリスト\n",
    "    '''\n",
    "    layers = []        # モジュールを格納するリスト\n",
    "    in_channels = 1024 # vggから出力される画像データのチャネル数\n",
    "\n",
    "    # vggに配置する畳み込み層のフィルター数(チャネル数に相当)\n",
    "    cfg = [256, 512,  # extras1\n",
    "           128, 256,  # extras2\n",
    "           128, 256,  # extras3\n",
    "           128, 256]  # extras4\n",
    "    \n",
    "    # extras1\n",
    "    # 出力の形状:(バッチサイズ, 512, 10, 10)\n",
    "    layers += [nn.Conv2d(in_channels,      # 入力時のチャネル数(1024)\n",
    "                         cfg[0],           # 出力時のチャネル数(256) \n",
    "                         kernel_size=(1))] # フィルターサイズ1×1\n",
    "    layers += [nn.Conv2d(cfg[0],           # 入力時のチャネル数(256)\n",
    "                         cfg[1],           # 出力時のチャネル数(512) \n",
    "                         kernel_size=(3),  # フィルターサイズ3×3\n",
    "                         stride=2,         # ストライドは2\n",
    "                         padding=1)]       # パディングのサイズは1\n",
    "    \n",
    "    # extras2    \n",
    "    # 出力の形状:(バッチサイズ, 256, 5, 5)\n",
    "    layers += [nn.Conv2d(cfg[1],           # 入力時のチャネル数(512)\n",
    "                         cfg[2],           # 出力時のチャネル数(128) \n",
    "                         kernel_size=(1))] # フィルターサイズ1×1\n",
    "    layers += [nn.Conv2d(cfg[2],           # 入力時のチャネル数(128)\n",
    "                         cfg[3],           # 出力時のチャネル数(256) \n",
    "                         kernel_size=(3),  # フィルターサイズ3×3\n",
    "                         stride=2,         # ストライドは2\n",
    "                         padding=1)]       # パディングのサイズは1\n",
    "    \n",
    "    # extras3\n",
    "    # 出力の形状:(バッチサイズ, 256, 3, 3)\n",
    "    layers += [nn.Conv2d(cfg[3],           # 入力時のチャネル数(256)\n",
    "                         cfg[4],           # 出力時のチャネル数(128)\n",
    "                         kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[4],           # 入力時のチャネル数(128)\n",
    "                         cfg[5],           # 出力時のチャネル数(256)\n",
    "                         kernel_size=(3))] # フィルターサイズ3×3\n",
    "    \n",
    "    # extras4\n",
    "    # 出力の形状:(バッチサイズ, 256, 1, 1)\n",
    "    layers += [nn.Conv2d(cfg[5],           # 入力時のチャネル数(256)\n",
    "                         cfg[6],           # 出力時のチャネル数(128)\n",
    "                         kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[6],           # 入力時のチャネル数(128)\n",
    "                         cfg[7],           # 出力時のチャネル数(256)\n",
    "                         kernel_size=(3))] # フィルターサイズ3×3\n",
    "\n",
    "    # リストlayersをnn.ModuleListに格納してReturnする\n",
    "    return nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374fbdb2-0d10-4d96-901b-e4a401d45403",
   "metadata": {},
   "outputs": [],
   "source": [
    "extras = make_extras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcd1da4-9ca4-427d-989d-28d3e642ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))】 ==> torch.Size([4, 256, 19, 19])\n",
      "【Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))】 ==> torch.Size([4, 512, 10, 10])\n",
      "【Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))】 ==> torch.Size([4, 128, 10, 10])\n",
      "【Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))】 ==> torch.Size([4, 256, 5, 5])\n",
      "【Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))】 ==> torch.Size([4, 128, 5, 5])\n",
      "【Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))】 ==> torch.Size([4, 256, 3, 3])\n",
      "【Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))】 ==> torch.Size([4, 128, 3, 3])\n",
      "【Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))】 ==> torch.Size([4, 256, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "sample = torch.randn((4, 1024, 19, 19))\n",
    "with torch.no_grad():\n",
    "    for i, layer in enumerate(extras):\n",
    "        sample = layer(sample)\n",
    "        if layer.__class__ != nn.modules.activation.ReLU:\n",
    "            print(f\"【{layer}】 ==> {sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca0a23-3b05-424e-b64a-1a43b4d1c4c8",
   "metadata": {},
   "source": [
    "extrasはvgg6の出力をinputとして、最終的に256チャンネル、1x1の特徴量マップとなる  \n",
    "extrasは大きな物体を検出に利用される  \n",
    "小さな物体は畳み込みの回数が少ないので検出性能が悪くなる傾向にある\n",
    "\n",
    "<img src=\"https://cvml-expertguide.net/wp-content/uploads/2022/11/d345a0950fcf9161a425919d0b8366ef.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035b763-5a82-410c-848a-014f67409462",
   "metadata": {},
   "source": [
    "一つの特徴量に一つのデフォルトボックスを用意すると合計が1940個になる\n",
    "\n",
    "- vgg4(out1):38x38\n",
    "- vgg6(out2):19x19\n",
    "- extras1(out3):10x10\n",
    "- extras2(out4):5x5\n",
    "- extras3(out5):3x3\n",
    "- extras4(out6):1x1\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/327077443/figure/fig5/AS:959259466539037@1605716687861/The-idea-of-default-boxes-applied-in-SSD-For-each-default-box-the-offsets-and.png\" width=500>\n",
    "\n",
    "実際はアスペクト比の異なるデフォルトボックスを複数用意するので合計は8732個になる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b853b6-e22a-46bd-9dd4-7b6919961047",
   "metadata": {},
   "source": [
    "# デフォルトボックスの位置補正用のレイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff75732-1126-4694-a040-0150684967a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loc(dbox_num=[4, 6, 6, 6, 4, 4]):\n",
    "    ''' デフォルトボックスのオフセットを出力するlocネットワークを生成\n",
    "    \n",
    "    Parameters:\n",
    "      dbox_num(intのリスト):\n",
    "          out1～out6それぞれに用意されるデフォルトボックスの数\n",
    "    Returns：\n",
    "      (nn.ModuleList): extrasのモジュール(部品)のリスト\n",
    "    '''\n",
    "    # ネットワークのモジュールを格納するリスト\n",
    "    loc_layers = []\n",
    "    # vgg4の畳み込み層3からの出力にL2Normでの正規化の処理を適用した\n",
    "    # out1に対する畳み込み層1\n",
    "    loc_layers += [nn.Conv2d(512,           # 入力時のチャネル数\n",
    "                             dbox_num[0]*4, # 出力時のチャネル数16\n",
    "                             kernel_size=3, # フィルターサイズ3×3\n",
    "                             padding=1)]    # パディングのサイズは1\n",
    "\n",
    "    # vgg6からの最終出力out2に対する畳み込み層2\n",
    "    loc_layers += [nn.Conv2d(1024,          # 入力時のチャネル数\n",
    "                             dbox_num[1]*4, # 出力時のチャネル数24\n",
    "                             kernel_size=3, # フィルターサイズ3×3\n",
    "                             padding=1)]    # パディングのサイズは1\n",
    "\n",
    "    # extrasのext1からの出力out3に対する畳み込み層3\n",
    "    loc_layers += [nn.Conv2d(512,           # 入力時のチャネル数\n",
    "                             dbox_num[2]*4, # 出力時のチャネル数24\n",
    "                             kernel_size=3, # フィルターサイズ3×3\n",
    "                             padding=1)]    # パディングのサイズは1\n",
    "\n",
    "    # extrasのext2からの出力out4に対する畳み込み層4\n",
    "    loc_layers += [nn.Conv2d(256,           # 入力時のチャネル数\n",
    "                             dbox_num[3]*4, # 出力時のチャネル数24\n",
    "                             kernel_size=3, # フィルターサイズ3×3\n",
    "                             padding=1)]    # パディングのサイズは1\n",
    "\n",
    "    # extrasのext3からの出力out5に対する畳み込み層5\n",
    "    loc_layers += [nn.Conv2d(256,           # 入力時のチャネル数\n",
    "                             dbox_num[4]*4, # 出力時のチャネル数16\n",
    "                             kernel_size=3, # フィルターサイズ3×3\n",
    "                             padding=1)]    # パディングのサイズは1\n",
    "\n",
    "    # extrasのext4からの出力out6に対する畳み込み層6\n",
    "    loc_layers += [nn.Conv2d(256,           # 入力時のチャネル数\n",
    "                             dbox_num[5]*4, # 出力時のチャネル数16\n",
    "                             kernel_size=3, # フィルターサイズ3×3\n",
    "                             padding=1)]    # パディングのサイズは1\n",
    "\n",
    "    # リストloc_layersをnn.ModuleListに格納してReturnする\n",
    "    return nn.ModuleList(loc_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7108fe4a-a93e-4aad-b04b-dd798019a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = make_loc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0960a3b-9583-41df-80e6-236416c959a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 16, 38, 38])\n",
      "【Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 24, 19, 19])\n",
      "【Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 24, 10, 10])\n",
      "【Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 24, 5, 5])\n",
      "【Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 16, 3, 3])\n",
      "【Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 16, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, layer in enumerate(loc):\n",
    "        if i == 0:\n",
    "            sample = torch.randn((4, 512, 38, 38))\n",
    "        elif i == 1:\n",
    "            sample = torch.randn((4, 1024, 19, 19))\n",
    "        elif i == 2:\n",
    "            sample = torch.randn((4, 512, 10, 10))\n",
    "        elif i == 3:\n",
    "            sample = torch.randn((4, 256, 5, 5))\n",
    "        elif i == 4:\n",
    "            sample = torch.randn((4, 256, 3, 3))\n",
    "        elif i == 5:\n",
    "            sample = torch.randn((4, 256, 1, 1))\n",
    "            \n",
    "        sample = layer(sample)\n",
    "        if layer.__class__ != nn.modules.activation.ReLU:\n",
    "            print(f\"【{layer}】 ==> {sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26600bc-0141-4006-9b24-5dec9e6a0071",
   "metadata": {},
   "source": [
    "locはデフォルトボックスの位置を学習する  \n",
    "out1、out3、out5には4つのデフォルトボックスを用意して、out2、out4、out6には6つのデフォルトボックスを用意する  \n",
    "デフォルトボックス毎に4次元(中心位置x, 中心位置y, 幅, 高さ)を出力するので  \n",
    "例えばout1は4x4=16のチャンネルになる  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d6820-9cd5-44ea-b828-14ca65befab1",
   "metadata": {},
   "source": [
    "# クラス確率出力用のレイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d621320f-7ae4-470d-8307-15da83894c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conf(classes_num=21, dbox_num=[4, 6, 6, 6, 4, 4]):\n",
    "    ''' デフォルトボックスに対する各クラスの確率を出力するネットワークを生成\n",
    "    \n",
    "    Parameters:\n",
    "      class_num(int): クラスの数\n",
    "      dbox_num(intのリスト):\n",
    "        out1～out6それぞれに用意されるデフォルトボックスの数\n",
    "        \n",
    "    Returns：\n",
    "      (nn.ModuleList): extrasのモジュール(部品)のリスト\n",
    "    '''\n",
    "    # ネットワークのモジュールを格納するリスト\n",
    "    conf_layers = []\n",
    "\n",
    "    # vgg4の畳み込み層3からの出力にL2Normでの正規化の処理を適用した\n",
    "    # out1に対する畳み込み層1\n",
    "    conf_layers += [nn.Conv2d(512,          # 入力時のチャネル数\n",
    "                              dbox_num[0]*classes_num, # 出力時は84\n",
    "                              kernel_size=3,# フィルターサイズ3×3\n",
    "                              padding=1)]   # パディングのサイズは1\n",
    "\n",
    "    # vgg6からの最終出力out2に対する畳み込み層2\n",
    "    conf_layers += [nn.Conv2d(1024,         # 入力時のチャネル数\n",
    "                              dbox_num[1]*classes_num, # 出力時は126\n",
    "                              kernel_size=3,# フィルターサイズ3×3\n",
    "                              padding=1)]   # パディングのサイズは1\n",
    "\n",
    "    # extrasのext1からの出力out3に対する畳み込み層3\n",
    "    conf_layers += [nn.Conv2d(512,          # 入力時のチャネル数\n",
    "                              dbox_num[2]*classes_num, # 出力時は126\n",
    "                              kernel_size=3,# フィルターサイズ3×3\n",
    "                              padding=1)]   # パディングのサイズは1\n",
    "\n",
    "    # extrasのext2からの出力out4に対する畳み込み層4\n",
    "    conf_layers += [nn.Conv2d(256,          # 入力時のチャネル数\n",
    "                              dbox_num[3]*classes_num, # 出力時は126\n",
    "                              kernel_size=3,# フィルターサイズ3×3\n",
    "                              padding=1)]   # パディングのサイズは1\n",
    "\n",
    "    # extrasのext3からの出力out5に対する畳み込み層5\n",
    "    conf_layers += [nn.Conv2d(256,          # 入力時のチャネル数\n",
    "                              dbox_num[4]*classes_num, # 出力時は84\n",
    "                              kernel_size=3,# フィルターサイズ3×3\n",
    "                              padding=1)]   # パディングのサイズは1\n",
    "\n",
    "    # extrasのext4からの出力out6に対する畳み込み層6\n",
    "    conf_layers += [nn.Conv2d(256,          # 入力時のチャネル数\n",
    "                              dbox_num[5]*classes_num, # 出力時は84\n",
    "                              kernel_size=3,# フィルターサイズ3×3\n",
    "                              padding=1)]   # パディングのサイズは1\n",
    "\n",
    "    # リストconf_layersをnn.ModuleListに格納してReturnする\n",
    "    return nn.ModuleList(conf_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f902bb2-66c7-48f3-9bb6-6c2b393023d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = make_conf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f97ba4-bef3-409f-8914-0c7381a564f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 84, 38, 38])\n",
      "【Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 126, 19, 19])\n",
      "【Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 126, 10, 10])\n",
      "【Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 126, 5, 5])\n",
      "【Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 84, 3, 3])\n",
      "【Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))】 ==> torch.Size([4, 84, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, layer in enumerate(conf):\n",
    "        if i == 0:\n",
    "            sample = torch.randn((4, 512, 38, 38))\n",
    "        elif i == 1:\n",
    "            sample = torch.randn((4, 1024, 19, 19))\n",
    "        elif i == 2:\n",
    "            sample = torch.randn((4, 512, 10, 10))\n",
    "        elif i == 3:\n",
    "            sample = torch.randn((4, 256, 5, 5))\n",
    "        elif i == 4:\n",
    "            sample = torch.randn((4, 256, 3, 3))\n",
    "        elif i == 5:\n",
    "            sample = torch.randn((4, 256, 1, 1))\n",
    "            \n",
    "        sample = layer(sample)\n",
    "        if layer.__class__ != nn.modules.activation.ReLU:\n",
    "            print(f\"【{layer}】 ==> {sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f04b8-d38f-40c1-ad1b-458529c7a326",
   "metadata": {},
   "source": [
    "confはデフォルトボックス毎のクラス確率を出力する  \n",
    "例えばout1はクラスの数(21)xデフォルトボックス(4)=84フィルタ数になる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727faa18-3849-42ed-8f00-c190d823cfc4",
   "metadata": {},
   "source": [
    "# デフォルトのバウンディングボックス生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "facd73ad-60e9-4f7b-afe5-a719c6861042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product as product\n",
    "from math import sqrt as sqrt\n",
    "\n",
    "class DBox(object):\n",
    "    '''8732個のDBoxの(x座標, y座標, 幅, 高さ)を生成する\n",
    "    \n",
    "    Attributes:\n",
    "      image_size(int): イメージのサイズ\n",
    "      feature_maps(list): out1～out6における特徴量マップのサイズのリストを保持\n",
    "      num_priors(int): feature_mapsの要素数、out1～out6の個数6を保持\n",
    "      steps(list): DBoxのサイズのリストを保持\n",
    "      min_sizes(list): 小さい正方形のDBoxのサイズを保持\n",
    "      max_sizes(list): 大きい正方形のDBoxのサイズを保持\n",
    "      aspect_ratios(list): 長方形のDBoxのアスペクト比を保持\n",
    "    '''\n",
    "    def __init__(self, cfg):\n",
    "        '''インスタンス変数の初期化を行う\n",
    "        '''\n",
    "        super(DBox, self).__init__() # スーパークラスのコンストラクターを実行\n",
    "\n",
    "        # 画像サイズ(300)を設定\n",
    "        self.image_size = cfg['input_size']\n",
    "        # out1～out6における特徴量マップのサイズ[38, 19, …]を設定\n",
    "        self.feature_maps = cfg['feature_maps']\n",
    "        # out1～out6の個数=6を設定\n",
    "        self.num_priors = len(cfg[\"feature_maps\"])\n",
    "        # DBoxのサイズ[8, 16, 32, …]を設定 \n",
    "        self.steps = cfg['steps']\n",
    "        # 小さい正方形のDBoxのサイズ[30, 60, 111, …] を設定\n",
    "        self.min_sizes = cfg['min_sizes']\n",
    "        # 大きい正方形のDBoxのサイズ[60, 111, 162, …] を設定\n",
    "        self.max_sizes = cfg['max_sizes']\n",
    "        # 長方形のDBoxのアスペクト比[[2],[2,3],[2,3], ...]を設定\n",
    "        self.aspect_ratios = cfg['aspect_ratios']\n",
    "\n",
    "    def make_dbox_list(self):\n",
    "        '''DBoxを作成する\n",
    "        \n",
    "        Returns:\n",
    "          (Tensor)DBoxの[cx, cy, width, height]を格納した(8732, 4)の形状のテンソル\n",
    "        '''\n",
    "        mean = []\n",
    "        # out1～out6における特徴量マップの数(6)だけ繰り返す\n",
    "        # 特徴量マップのサイズのリストからインデックスをk、サイズをfに取り出す\n",
    "        # 'feature_maps': [38, 19, 10, 5, 3, 1]\n",
    "        # k: 0,1,2,3,4,5\n",
    "        # f: 38, 19, 10, 5, 3, 1\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            # fまでの数をrepeat=2を指定して2つのリストにして組み合わせ(直積)を作る\n",
    "            # f=38の場合\n",
    "            # i: 0,0,0,0,... の38個の0に対して\n",
    "            # j: 0,1,2,3, ..., 37を組み合わせる\n",
    "            # (i,j)は(0,0)(0,1)...(0,37)~(37,0)...(37,37)\n",
    "            for i, j in product(range(f), repeat=2):  \n",
    "                # 特徴量の画像サイズをDBoxのサイズsteps[k]で割る(kはインデックス)\n",
    "                # 300 / 'steps': [8, 16, 32, 64, 100, 300]\n",
    "                f_k = self.image_size / self.steps[k]\n",
    "\n",
    "                # 特徴量ごとのDBoxの中心のx座標、y座標を求める\n",
    "                # (0～1の範囲に規格化)\n",
    "                cx = (j + 0.5) / f_k\n",
    "                cy = (i + 0.5) / f_k\n",
    "\n",
    "                # 小さい正方形のDBoxのサイズmin_sizes[k](kはインデックス)を\n",
    "                # 画像のサイズで割る\n",
    "                # 'min_sizes': [30, 60, 111, 162, 213, 264] / 300\n",
    "                s_k = self.min_sizes[k]/self.image_size\n",
    "                # 小さい正方形のDBoxの[cx,cy, width, height]をリストに追加\n",
    "                mean += [cx, cy, s_k, s_k]\n",
    "\n",
    "                # 大きい正方形のDBoxのサイズmin_sizes[k](kはインデックス)を\n",
    "                # 画像のサイズで割る\n",
    "                # max_sizes': [45, 99, 153, 207, 261, 315] / 300\n",
    "                # さらにs_kを掛けて平方根を求める\n",
    "                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))\n",
    "                # 大きい正方形のDBoxの[cx,cy, width, height]をリストに追加\n",
    "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
    "\n",
    "                # 長方形のDBoxの[cx,cy, width, height]をリストに追加\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    # widthはs_kにアスペクト比の平方根を掛けたもの\n",
    "                    # heightはs_kをアスペクト比と平方根で割ったもの\n",
    "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
    "                    # widthはs_kをアスペクト比と平方根で割ったもの\n",
    "                    # heightはs_kにアスペクト比の平方根を掛けたもの\n",
    "                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
    "\n",
    "        # DBoxの[cx,cy, width, height]のリストを(8732, 4)の2階テンソルに変換\n",
    "        output = torch.Tensor(mean).view(-1, 4)\n",
    "        # DBoxの大きさが1を超えている場合は1にする\n",
    "        output.clamp_(max=1, min=0)\n",
    "        \n",
    "        # DBoxの[cx,cy, width, height]を格納した2階テンソルを返す\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fb445-6670-4f65-b1b1-f33bb626d89c",
   "metadata": {},
   "source": [
    "# 全体のアーキテクチャ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbffb643-d8f8-4ec0-acb9-2dbad69d3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caa9cd03-7c8e-4650-9be9-e4ede200dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssd import make_vgg, make_extras, L2Norm, DBox, Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca6991d-7572-4e81-9dd0-89b719e7e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Module):\n",
    "    '''SSDモデルを生成するクラス\n",
    "    \n",
    "    Attributes:\n",
    "      phase(str): 'train'または'test'\n",
    "      classes_num(int): クラスの数\n",
    "      vgg(object): vggネットワーク\n",
    "      extras(object): extrasネットワーク\n",
    "      L2Norm(object): L2norm層\n",
    "      loc(object): locネットワーク\n",
    "      conf(object): confネットワーク\n",
    "      dbox_list(Tensor):\n",
    "        DBoxの[cx, cy, width, height]を格納した(8732, 4)の形状のテンソル\n",
    "      detect(object):\n",
    "        Detectクラスのforward()を実行する関数オブジェクト\n",
    "    '''\n",
    "    def __init__(self, phase, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 動作モード(train or test)\n",
    "        self.phase = phase\n",
    "        # クラス数\n",
    "        self.classes_num = cfg[\"classes_num\"]\n",
    "        \n",
    "        self.vgg = make_vgg()\n",
    "        self.extra = make_extras()\n",
    "        self.l2norm = L2Norm()\n",
    "        \n",
    "        # dbox_numはout1~out6までに用意するデフォルトボックスの数\n",
    "        self.loc = make_loc(cfg[\"dbox_num\"])\n",
    "        self.conf = make_conf(cfg[\"classes_num\"], cfg[\"dbox_num\"])\n",
    "        \n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        # 推論で利用する場合\n",
    "        if phase == \"test\":\n",
    "            self.detect = Detect.appy\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (バッチサイズ, 3, 300, 300)\n",
    "        \"\"\"\n",
    "        \n",
    "        # 出力を保存するリスト\n",
    "        out_list, loc, conf = [], [], []\n",
    "        \n",
    "        # vggネットワークinputを通す(index23は4層まで)\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "            \n",
    "        # vgg4の出力をL2Normに通して保存\n",
    "        out1 = self.l2norm(x)\n",
    "        out_list.append(out1)\n",
    "        \n",
    "        # vgg残りの層を通す\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        \n",
    "        # vgg6の出力をappend\n",
    "        out_list.append(x)\n",
    "        \n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inpalce=True)\n",
    "            if k % 2 == 1:\n",
    "                # out3-out6を追加\n",
    "                out_list.append(x)\n",
    "        \n",
    "        # out1-out6を位置情報レイヤーとクラス分類レイヤーに渡す\n",
    "        for (x, l, c) in zip(out_list, self.loc, self.conf):\n",
    "            # (バッチサイズ, オフセット値4*DBoxの種類, 特徴量(h),特徴量(w))から\n",
    "            # (バッチサイズ, 特徴量(h), 特徴量(w), オフセット値4*DBoxの種類)の変換\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "            \n",
    "        # flat化\n",
    "        # loc:(バッチサイズ, 34928)\n",
    "        # conf:(バッチサイズ, 183372)\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "        \n",
    "        # デフォルトボックスx4つのオフセット値のshapeにする\n",
    "        # (バッチサイズ, 8732, 4)\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        # デフォルトボックスxクラス数のshapeにする\n",
    "        # (バッチサイズ, 8732, 21)\n",
    "        conf = conf.view(conf.size(0), -1, self.classes_num)\n",
    "        \n",
    "        # outputとしてまとめる\n",
    "        output = (loc, conf, self.dbox_list)\n",
    "        \n",
    "        if self.phase == \"test\":\n",
    "            # 推論時は確信度と位置情報を後処理して\n",
    "            # (バッチサイズ, 21(クラス), 200(Top200のBBox), 5) としてreturnされる\n",
    "            # 最後の次元の5は[BBoxの確信度, xmin, ymin, width, height]\n",
    "            self.detect(*output)\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a7cd5-a48c-47b1-9b9a-e69bb1ddfbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
